{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s3/4_v45d_95z50nf91d00rdv9c0000gn/T/ipykernel_1072/3682808887.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmat4py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#import ot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/stumpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistributionNotFound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmass\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstump\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstump\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstumped\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstumped\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/stumpy/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaximum_filter1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_filter1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/scipy/signal/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwaveforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_max_len_seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmax_len_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/scipy/signal/windows/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \"\"\"\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwindows\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m __all__ = ['boxcar', 'triang', 'parzen', 'bohman', 'blackman', 'nuttall',\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/scipy/signal/windows/windows.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp_fft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m __all__ = ['boxcar', 'triang', 'parzen', 'bohman', 'blackman', 'nuttall',\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpecialFunctionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpecialFunctionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ufuncs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_ufuncs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mat4py\n",
    "import stumpy\n",
    "import matplotlib.pylab as pl\n",
    "#import ot \n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vmdpy import VMD \n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SensorList', 'nSensors', 'EventIDs', 'X', 'nTests', 'nDamagedTests', 'nHealthyTests', 'EventSizes', 'labels_binary', 'F'])\n",
      "Total number of sensors: 24\n",
      "Total number of tests: 270\n",
      "\n",
      "Total number of healthy data: 150\n",
      "Total number of damage data: 120\n",
      "\n",
      "Total number of data instances: 6480 (which is equal to 24 sensors x 270 events)\n",
      "Length of each data recording: 8192\n",
      "Data processed for sensor 1.\n",
      "Data processed for sensor 2.\n",
      "Data processed for sensor 3.\n",
      "Data processed for sensor 4.\n",
      "Data processed for sensor 5.\n",
      "Data processed for sensor 6.\n",
      "Data processed for sensor 7.\n",
      "Data processed for sensor 8.\n",
      "Data processed for sensor 9.\n",
      "Data processed for sensor 10.\n",
      "Data processed for sensor 11.\n",
      "Data processed for sensor 12.\n",
      "Data processed for sensor 13.\n",
      "Data processed for sensor 14.\n",
      "Data processed for sensor 15.\n",
      "Data processed for sensor 16.\n",
      "Data processed for sensor 17.\n",
      "Data processed for sensor 18.\n",
      "Data processed for sensor 19.\n",
      "Data processed for sensor 20.\n",
      "Data processed for sensor 21.\n",
      "Data processed for sensor 22.\n",
      "Data processed for sensor 23.\n",
      "Data processed for sensor 24.\n",
      "Time Taken: 69.44s\n"
     ]
    }
   ],
   "source": [
    "# Previous data structure from a prior data61 collaboration \n",
    "# Not the form you would find on the previous website\n",
    "\n",
    "# Input file is .mat type from Matlab --- engineering collaborations\n",
    "data = mat4py.loadmat('Building_Model.mat')\n",
    "print(data.keys())\n",
    "\n",
    "# Extracting columns\n",
    "nTests = data['nTests']\n",
    "nHealthy = data['nHealthyTests']\n",
    "nDamage = data['nDamagedTests']\n",
    "nSensors = data['nSensors']\n",
    "X = data['X']\n",
    "\n",
    "# Constructing columns for new data frame (which will be defined later)\n",
    "info_cols = ['y_labels','damage_location','damage_level','voltage_level']\n",
    "X_cols_time = ['Xt_'+str(i) for i in range(len(X[0]))]\n",
    "cols = [X_cols_time + info_cols]\n",
    "\n",
    "print('Total number of sensors: '+str(nSensors))\n",
    "print('Total number of tests: '+str(nTests))\n",
    "print()\n",
    "print('Total number of healthy data: '+str(data['nHealthyTests']))\n",
    "print('Total number of damage data: '+str(data['nDamagedTests']))\n",
    "print()\n",
    "print('Total number of data instances: '+str(len(X)) + ' (which is equal to 24 sensors x 270 events)') # There are 24 sensors x 270 events = 6480 data instances \n",
    "print('Length of each data recording: '+str(len(X[0]))) # Each data recording is 8192 longn sampled at 1600 hz = 1600 samples/sec\n",
    "\n",
    "len(data[\"labels_binary\"]) #healthy or not. labels are arranged linearly (1st sensor is the first 270 datapoints)\n",
    "data[\"EventIDs\"]\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "data_dict = {}\n",
    "# Should I do some nise reduction in input signals???\n",
    "for i in range(1,nSensors+1):\n",
    "    \n",
    "    # Extracting Data   \n",
    "    X_time = X[nTests*(i-1):nTests*i]\n",
    "    y = data['labels_binary'][nTests*(i-1):nTests*i] # collects LXX, DXX and VXX information\n",
    "    locations = [ L[0][0:3] for L in data['EventIDs'][nTests*(i-1):nTests*i] ]\n",
    "    damage_levels = [ L[0][4:7] for L in data['EventIDs'][nTests*(i-1):nTests*i] ] \n",
    "    shaker_voltage = [ L[0][8:11] for L in data['EventIDs'][nTests*(i-1):nTests*i] ]\n",
    "    \n",
    "    # Building Lists for Pandas\n",
    "    sensor_data = []\n",
    "    for j in range(len(X_time)):\n",
    "        sensor_data.append(X_time[j]+y[j]+[locations[j]]+[damage_levels[j]]+[shaker_voltage[j]]) \n",
    "    \n",
    "    # Constructing Time DataFrame\n",
    "    sensor_time_df = pd.DataFrame(data=sensor_data, columns=cols) # \n",
    "    data_dict['Sensor'+str(i)] = sensor_time_df #\n",
    "    \n",
    "    print(f'Data processed for sensor {i}.')\n",
    "    \n",
    "time_end = time.time()\n",
    "\n",
    "print(f'Time Taken: {time_end-time_start:.2f}s')\n",
    "\n",
    "sens1 = data_dict[\"Sensor1\"] \n",
    "\n",
    "sens1.to_csv(\"sens1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "# plot function\n",
    "def multiplot(data, orientation = \"vertical\", col_names = False):\n",
    "    '''data is a list of datasets to be plotted. '''\n",
    "    n = len(data) \n",
    "    if orientation == \"vertical\":\n",
    "        fig, axs = plt.subplots(1,n,sharey=True)\n",
    "    elif orientation == \"horizontal\":\n",
    "        fig, axs = plt.subplots(n,1, sharex=True)\n",
    "    fig.suptitle(\"Comparing differing damage levels\")\n",
    "    fig.set_size_inches(15,10)\n",
    "    for i in range(n):\n",
    "        axs[i].plot(data[i].values, linewidth=0.2)\n",
    "        if col_names != False: \n",
    "            axs[i].set_xlabel(col_names[i])\n",
    "            axs[i].set_ylabel(\"Amplitude\")\n",
    "\n",
    "    return \n",
    "\n",
    "# Boolean for df.apply()\n",
    "def boolean_rows(a):\n",
    "    return(a[0] & a[1] & a[2])\n",
    "\n",
    "def extract_inf(sens):\n",
    "    '''\n",
    "    Input: sens is dataframe (as in usual input, like data_dict[\"Sensor1\"].iloc[i] (ith test)'''\n",
    "    y = sens[\"y_labels\"]\n",
    "    loc = sens[\"damage_location\"]\n",
    "    dam_level = sens[\"damage_level\"]\n",
    "    volt = sens[\"voltage_level\"]\n",
    "    data = sens[:-4]\n",
    "    return data, y, loc, dam_level, volt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [['L00','D00','V08'],   ['L1C','DB0','V08'],     ['L1C','DBB','V08'],      ['L13','DBB','V08']]\n",
    "col_names = [[\"damage_location\"], [\"damage_level\"], [\"voltage_level\"]]\n",
    "\n",
    "# Generating TS_CAT \n",
    "L00_D = [] #initialise lists for indicators, rows, then data\n",
    "data_L00_D = []\n",
    "ind_D = []\n",
    "num_samples = 5 # number of segments you wish to extract from each type of data\n",
    "\n",
    "for i in range(len(cases)):\n",
    "    ind_D.append(sens1[col_names]==cases[i]) # turn the indicators into a single T/F and find corresponding rows\n",
    "    L00_D.append(sens1[ind_D[i].apply(boolean_rows, axis=1)])\n",
    "    data = L00_D[i].iloc[0:num_samples, :-4]\n",
    "    data_L00_D.append(data)\n",
    "\n",
    "ts_pre_cat = []\n",
    "for j in range(len(cases)):\n",
    "    temp_data = []\n",
    "    for i in range(num_samples):\n",
    "        temp_data.append(data_L00_D[j].iloc[i,:])\n",
    "    ts_pre_cat.append(pd.concat(temp_data))\n",
    "ts_cat = pd.concat(ts_pre_cat)\n",
    "\n",
    "ts_cat.to_csv(\"ts_cat_555.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0b4122ef01287e772364b46c8ab7fc191b99504e2c60fdea0ffe2ad0e9109c5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
